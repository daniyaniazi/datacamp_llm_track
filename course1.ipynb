{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39869235-425b-4d2b-a0b8-5a20e0ba544e",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0e585-e2c8-45c0-825d-8afef423f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25024273-c2e9-4222-98fe-ccf5db3a843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "in_tensor = torch.tensor([[0.7,0.8,0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d5d0ba5-8bd0-4fa6-9437-65fb3c057937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dffe7c31-f41e-4d80-aaea-aac77cfee4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c644c75f-02c5-4b62-9c60-85583a20abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8321]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])\n",
    "\n",
    "# Implement a small neural network with exactly two linear layers\n",
    "model = nn.Sequential( nn.Linear(1*8, 8),\n",
    "                       nn.Linear(1*8, 1)\n",
    "                     )\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b931c54-150f-4c6a-aee9-762796ea1af7",
   "metadata": {},
   "source": [
    "Sigmoid functions are used for binary classification problems, whereas softmax functions are often used for multiclass classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "279a78e9-682f-47df-b833-6920fe12ad90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6900]])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor([[0.8]])\n",
    "\n",
    "# Create a sigmoid function and apply it on input_tensor\n",
    "sigmoid = nn.Sigmoid()\n",
    "probability = sigmoid(input_tensor)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b22efcd5-390b-4daf-bdfe-20d845d74bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2828e-01, 1.1698e-04, 5.7492e-01, 3.4961e-02, 1.5669e-01, 1.0503e-01]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.tensor([[1.0, -6.0, 2.5, -0.3, 1.2, 0.8]])\n",
    "\n",
    "# Create a softmax function and apply it on input_tensor\n",
    "softmax = nn.Softmax(dim=-1)\n",
    "probabilities = softmax(input_tensor)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c88bcbfb-7a73-42a4-93f6-dc3bd85047f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2522, 0.3094, 0.1491, 0.2893]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 4),\n",
    "  nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb4d65-dafe-4c6a-85fe-d13822d47a01",
   "metadata": {},
   "source": [
    "# One Hot Encodinng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c4e4794-db01-41f0-82dc-4b8b2fe43cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# CLASS 1,2,3 Onehot enccoding\n",
    "\n",
    "F.one_hot(torch.tensor(0), num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6aaa991-e6b5-4172-a858-479b6a0e2bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(1), num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0da7d5c3-3d95-4e83-9225-35e8068d0adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(2), num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a6a90ab-28fd-48de-a186-c2ce140fbfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using NumPy\n",
    "one_hot_numpy = np.array([0,1,0])\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch =F.one_hot(torch.tensor(y), num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de5542-4450-48c9-bee3-29df2c42f91a",
   "metadata": {},
   "source": [
    "# Cross Etropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5637764a-fb6c-4a4b-ac17-dcb953d6d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7af32e0-3ace-4b6e-acf0-f6e43859bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.tensor([[-0.1211,0.1059]])\n",
    "one_hot_target = torch.tensor([[1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d2fa0a1-121a-4cc0-a9c2-d82031d3b81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8131, dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "criterion(scores.double(),one_hot_target.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913da4b-9e0a-4bd0-95c3-c672281c525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(),one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bed142-7e8e-4f3a-8063-959f6cfcb309",
   "metadata": {},
   "source": [
    "# Backpropogation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc269fd2-8db8-4025-b7c5-2f9fb56fce62",
   "metadata": {},
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23cfb667-94dd-4804-b5a5-97708b1354c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=11, out_features=20, bias=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0] # layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cebe4ca7-5e6c-4f5b-b3bc-310ca359b7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.grad , model[0].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40429d-6767-4598-9110-9db497290011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "\n",
    "weight = model[0].weight\n",
    "weight_grad = model[0].weight.grad\n",
    "weight = weight - lr * weight_grad\n",
    "\n",
    "bias = model[0].bias\n",
    "bias_grad = model[0].bias.grad\n",
    "bias = weight - lr * bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee82a794-2c05-4eff-a304-bbb6be551211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer  = optim.SGD(model.parameters(), lr = 0.0001)\n",
    "optmizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4a5207e3-5d2f-421b-8fb8-d215e4cd62ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Linear(8, 2)\n",
    "                     )\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight_0 = model[0].weight\n",
    "\n",
    "# Access the bias of the second linear layer\n",
    "bias_1 = model[1].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7731323-498e-4bcf-aa3b-27e3ca8827fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = nn.LeakyRelu(negative_slope = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c17ce2-b175-45f4-9ec6-085277712f36",
   "metadata": {},
   "source": [
    "# TRAIN A NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "00b99f5e-af73-4c45-85cc-e18964492a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_loss(prediction, target):\n",
    "    return np.mean((prediction - target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e3d43-cb16-46cd-bbaa-6f2b4175e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = nn.MSELoss()\n",
    "loss = MSE(prediction,target) # float tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152f38c-6e07-446d-8a92-d3207f9a555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "dataset = TensorDataset(torch.tensor(features).float(), torch.tensor(target).float())\n",
    "dataloader =  DataLoader(dataset , batch_size=4,shuffle=True)\n",
    "\n",
    "for batch_inputs, batch_labels in dataloader:\n",
    "    \n",
    "\n",
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Linear(8, 2)\n",
    "                     )\n",
    "MSE = nn.MSELoss()\n",
    "optimizer  = optim.SGD(model.parameters(), lr = 0.0001, momentum=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7182ce-fbf7-44aa-aa63-99defb60471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    for data in dataLoader:\n",
    "        # set gradient to 0\n",
    "        optimizer.zero_grad()\n",
    "        feature , target = data\n",
    "        pred = model(feature)\n",
    "        loss  = MSE (pred,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e14c9-0f64-4a45-88ed-dc8c73fa9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ReLU function with PyTorch\n",
    "relu_pytorch = nn.ReLU()\n",
    "\n",
    "# Apply your ReLU function on x, and calculate gradients\n",
    "x = torch.tensor(-1.0, requires_grad=True)\n",
    "y = relu_pytorch(x)\n",
    "\n",
    "# Calculate gradients\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient of the ReLU function for x\n",
    "gradient = x.grad\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691e6abd-f4e9-4fa5-84b8-3c8027050d72",
   "metadata": {},
   "source": [
    ".numel() returns the no of elements in tensor\n",
    "\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06219f37-72dc-476d-98de-234a79395c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 4),\n",
    "                      nn.Linear(4, 2),\n",
    "                      nn.Linear(2, 1))\n",
    "\n",
    "total = 0\n",
    "\n",
    "# Calculate the number of parameters in the model\n",
    "for param in model.parameters():\n",
    "  total += param.numel()\n",
    "\n",
    "for name,param in model.parameters():\n",
    "  if name == '0.weight':\n",
    "      param.requires_grad = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e3d0f4-4789-48fd-aa14-8cd02f4597b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():    \n",
    "  \n",
    "    # Check if the parameters belong to the first layer\n",
    "    if name == '0.weight' or name == '0.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False \n",
    "  \n",
    "    # Check if the parameters belong to the second layer\n",
    "    if name == '1.weight' or name == '1.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a8107-a591-42f9-ac5b-18483208cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Linear(65,128)\n",
    "layer.weight.min(), layer.weight.max()\n",
    "\n",
    "nn.layer0 = nn.Linear(16, 32)\n",
    "layer1 = nn.Linear(32, 64)\n",
    "\n",
    "# Use uniform initialization for layer0 and layer1 weights\n",
    "nn.init.uniform_(layer0.weight)\n",
    "nn.init.uniform_(layer1.weight)\n",
    "\n",
    "model = nn.Sequential(layer0, layer1)(layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef49c50-e353-4ade-b663-c253a6d8008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(dataframe[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].to_numpy()).float()\n",
    "target = torch.tensor(dataframe['Potability'].to_numpy()).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)\n",
    "\n",
    "# Create a dataloader using the above dataset\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "x, y = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c687c-19f3-47f6-81d8-1bc4c1d473b3",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "Add dropout\n",
    "weight decay\n",
    "augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6458537d-b31a-4ea8-869c-a9ce74c7ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(4, 4),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(p=0.5))\n",
    "# Behaves Differently durinmg testing and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4d617e87-e245-4040-ae93-ec1e9a914f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.randn((1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "01cbd867-742b-44dd-adb8-c5b232d4eec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()  # Set the model to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "841c1e43-0c0e-4597-a084-14b1776057d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output before Dropout: tensor([[0.4013, 0.0382, 0.0000, 0.6071]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output_before_dropout = model[0](features)  # Apply the first Linear layer\n",
    "output_before_dropout = model[1](output_before_dropout)  # Apply ReLU activation\n",
    "print(\"Output before Dropout:\", output_before_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "486624aa-29ef-41c2-aa25-af17ee5137c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after Dropout: tensor([[0.8026, 0.0765, 0.0000, 1.2142]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_after_dropout = model[2](output_before_dropout)  # Apply Dropout\n",
    "print(\"Output after Dropout:\", output_after_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d29347-f373-476c-828e-d811ce964943",
   "metadata": {},
   "source": [
    "# WEIGHT DECAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d9588a9b-7d99-4307-badc-1b1e50afaf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "optmizer = optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# weight decay between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f17b1d-95b8-41c1-b1c7-ecb46c6559ed",
   "metadata": {},
   "source": [
    "# Fine Tunning\n",
    "Use Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a574c519-9b33-4b9e-a837-ccb7897d4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor in range(2,6):\n",
    "    lr = 10** -factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a09147a6-f179-4178-a8a2-1cf14a67e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = np.random.uniform(2,6)\n",
    "lr = 10** -factor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL Env",
   "language": "python",
   "name": "global_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
